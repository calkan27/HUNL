--- a/eval_cli.py
+++ b/eval_cli.py
@@ -182,54 +182,49 @@
 
 def main(argv: Optional[List[str]] = None) -> None:
 
-	parser = argparse.ArgumentParser(description="Evaluate agents with naive vs AIVAT-corrected estimates.")
-	parser.add_argument("--mode", choices=["agent-vs-agent", "agent-vs-policy"], default="agent-vs-agent")
-	parser.add_argument("--episodes", type=int, default=50)
-	parser.add_argument("--seed", type=int, default=1729)
-	parser.add_argument("--num-clusters", type=int, default=1000)
-	parser.add_argument("--depth-limit", type=int, default=1)
-	parser.add_argument("--iterations", type=int, default=8)
-	parser.add_argument("--river-buckets", type=int, default=0)
-	args = parser.parse_args(argv)
-
-	cfg = ResolveConfig.from_env(
-			{
-					"num_clusters": int(args.num_clusters),
-					"depth_limit": int(args.depth_limit),
-					"total_iterations": int(args.iterations),
-			}
-	)
-	if int(args.river_buckets) > 0:
-			try:
-					setattr(cfg, "river_num_buckets", int(args.river_buckets))
-			except Exception:
-					pass
-
-	results = _run_matches(args.mode, args.episodes, args.seed, cfg)
-	mean_na, mean_av, std_na, std_av, reduction = _summarize(results)
-	bm = _block_metrics(results, block_size=100)
-
-	print("====================================")
-	print(f"Mode: {args.mode}")
-	print(f"Episodes: {args.episodes}")
-	print("------------------------------------")
-	print(f"Naive average reward (agent 0): {mean_na:.6f}")
-	print(f"AIVAT-corrected estimate      : {mean_av:.6f}")
-	print(f"Std dev (naive)               : {std_na:.6f}")
-	print(f"Std dev (AIVAT)               : {std_av:.6f}")
-	print(f"Std reduction vs naive        : {reduction*100.0:.2f}%")
-	print("------------------------------------")
-	print(f"Blocks (100 hands)            : {bm['blocks']}")
-	print(f"Naive chips/100               : {bm['naive']['mbb100']:.2f}  CI95=({bm['naive']['ci95'][0]:.2f},{bm['naive']['ci95'][1]:.2f})")
-	print(f"AIVAT chips/100               : {bm['aivat']['mbb100']:.2f}  CI95=({bm['aivat']['ci95'][0]:.2f},{bm['aivat']['ci95'][1]:.2f})")
-	print("====================================")
-
-
-	def _chance_policy_uniform(node: GameNode) -> Dict[str, float]:
-		ps = node.public_state
-		used = set(list(getattr(ps, "board_cards", [])))
-		deck = [c for c in DECK if c not in used]
-		if not deck:
-			return {}
-		u = 1.0 / float(len(deck))
-		return {c: u for c in deck}
+        parser = argparse.ArgumentParser(description="Evaluate agents with naive vs AIVAT-corrected estimates.")
+        parser.add_argument("--mode", choices=["agent-vs-agent", "agent-vs-policy"], default="agent-vs-agent")
+        parser.add_argument("--episodes", type=int, default=50)
+        parser.add_argument("--seed", type=int, default=1729)
+        parser.add_argument("--num-clusters", type=int, default=1000)
+        parser.add_argument("--depth-limit", type=int, default=1)
+        parser.add_argument("--iterations", type=int, default=8)
+        parser.add_argument("--river-buckets", type=int, default=0)
+        args = parser.parse_args(argv)
+
+        cfg = ResolveConfig.from_env(
+                        {
+                                        "num_clusters": int(args.num_clusters),
+                                        "depth_limit": int(args.depth_limit),
+                                        "total_iterations": int(args.iterations),
+                        }
+        )
+        if int(args.river_buckets) > 0:
+                        try:
+                                        setattr(cfg, "river_num_buckets", int(args.river_buckets))
+                        except Exception:
+                                        pass
+
+        results = _run_matches(args.mode, args.episodes, args.seed, cfg)
+        mean_na, mean_av, std_na, std_av, reduction = _summarize(results)
+        bm = _block_metrics(results, block_size=100)
+
+        print("====================================")
+        print(f"Mode: {args.mode}")
+        print(f"Episodes: {args.episodes}")
+        print("------------------------------------")
+        print(f"Naive average reward (agent 0): {mean_na:.6f}")
+        print(f"AIVAT-corrected estimate      : {mean_av:.6f}")
+        print(f"Std dev (naive)               : {std_na:.6f}")
+        print(f"Std dev (AIVAT)               : {std_av:.6f}")
+        print(f"Std reduction vs naive        : {reduction*100.0:.2f}%")
+        print("------------------------------------")
+        print(f"Blocks (100 hands)            : {bm['blocks']}")
+        print(f"Naive chips/100               : {bm['naive']['chips100']:.2f}  CI95=({bm['naive']['ci95_chips100'][0]:.2f},{bm['naive']['ci95_chips100'][1]:.2f})")
+        print(f"Naive bb/100                  : {bm['naive']['bb100']:.2f}  CI95=({bm['naive']['ci95_bb100'][0]:.2f},{bm['naive']['ci95_bb100'][1]:.2f})")
+        print(f"Naive mbb/g                   : {bm['naive']['mbb_g']:.2f}  CI95=({bm['naive']['ci95_mbb_g'][0]:.2f},{bm['naive']['ci95_mbb_g'][1]:.2f})")
+        print(f"AIVAT chips/100               : {bm['aivat']['chips100']:.2f}  CI95=({bm['aivat']['ci95_chips100'][0]:.2f},{bm['aivat']['ci95_chips100'][1]:.2f})")
+        print(f"AIVAT bb/100                  : {bm['aivat']['bb100']:.2f}  CI95=({bm['aivat']['ci95_bb100'][0]:.2f},{bm['aivat']['ci95_bb100'][1]:.2f})")
+        print(f"AIVAT mbb/g                   : {bm['aivat']['mbb_g']:.2f}  CI95=({bm['aivat']['ci95_mbb_g'][0]:.2f},{bm['aivat']['ci95_mbb_g'][1]:.2f})")
+        print("====================================")
+
