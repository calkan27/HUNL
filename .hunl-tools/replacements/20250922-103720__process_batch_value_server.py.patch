--- a/value_server.py
+++ b/value_server.py
@@ -19,54 +19,43 @@
             self._thr: Optional[threading.Thread] = None
             self._counters: Dict[str, int] = {"preflop": 0, "flop": 0, "turn": 0, "river": 0}
 
-    def _process_batch(self, stages: List[str], xs: List[torch.Tensor], scale_flags: List[bool], handles: List[_ResultHandle]) -> None:
-        idx_by_stage: Dict[str, List[int]] = {}
-        for i, st in enumerate(stages):
-            idx_by_stage.setdefault(st, []).append(i)
-        for st, idxs in idx_by_stage.items():
-            model = self.models.get(st)
-            if model is None or len(idxs) == 0:
-                for i in idxs:
-                    handles[i].set((torch.zeros(1, 0), torch.zeros(1, 0)))
-                continue
-            with torch.no_grad():
-                batch = torch.cat([xs[i].to(self.device) for i in idxs], dim=0)
-                K = int(getattr(model, "num_clusters", 0))
-                start_r1 = 1 + 52
-                end_r1 = start_r1 + K
-                start_r2 = end_r1
-                end_r2 = start_r2 + K
-                r1 = batch[:, start_r1:end_r1]
-                r2 = batch[:, start_r2:end_r2]
-                p1, p2 = model(batch)
-                f1, f2 = model.enforce_zero_sum(r1, r2, p1, p2)
-                self._counters[str(st)] = int(self._counters.get(str(st), 0)) + int(batch.shape[0])
-                if any(scale_flags):
-                    pot_norm = batch[:, 0:1]
-                    for j, i in enumerate(idxs):
-                        if scale_flags[i]:
-                            sel = j
-                            scale = pot_norm[sel:sel+1, :]
-                            v1 = f1[sel:sel+1, :] * scale
-                            v2 = f2[sel:sel+1, :] * scale
-                        else:
-                            v1 = f1[j:j+1, :]
-                            v2 = f2[j:j+1, :]
-                        handles[i].set((v1, v2))
-                else:
-                    for j, i in enumerate(idxs):
-                        handles[i].set((f1[j:j+1, :], f2[j:j+1, :]))
-
-	def query(self, stage: str, inputs: torch.Tensor, scale_to_pot: bool = False, as_numpy: bool = True) -> Tuple[Any, Any]:
-		if inputs.dim() == 1:
-			inputs = inputs.unsqueeze(0)
-		self.start()
-		h = _ResultHandle()
-		self._q.put((str(stage), inputs.detach().clone(), bool(scale_to_pot), h))
-		return h.result(as_numpy=as_numpy)
-
-	def query_many(self, stage: str, batch_inputs: torch.Tensor, scale_to_pot: bool = False, as_numpy: bool = True) -> Tuple[Any, Any]:
-		return self.query(stage, batch_inputs, scale_to_pot=scale_to_pot, as_numpy=as_numpy)
+    def _process_batch(self, stages: List[str], xs: List[torch.Tensor], scale_flags: List[bool], handles):
+            idx_by_stage: Dict[str, List[int]] = {}
+            for i, st in enumerate(stages):
+                    idx_by_stage.setdefault(st, []).append(i)
+            for st, idxs in idx_by_stage.items():
+                    model = self.models.get(st)
+                    if model is None or len(idxs) == 0:
+                            for i in idxs:
+                                    handles[i].set((torch.zeros(1, 0), torch.zeros(1, 0)))
+                            continue
+                    with torch.no_grad():
+                            batch = torch.cat([xs[i].to(self.device) for i in idxs], dim=0)
+                            K = int(getattr(model, "num_clusters", 0))
+                            start_r1 = 1 + 52
+                            end_r1 = start_r1 + K
+                            start_r2 = end_r1
+                            end_r2 = start_r2 + K
+                            r1 = batch[:, start_r1:end_r1]
+                            r2 = batch[:, start_r2:end_r2]
+                            p1, p2 = model(batch)
+                            f1, f2 = model.enforce_zero_sum(r1, r2, p1, p2)
+                            self._counters[str(st)] = int(self._counters.get(str(st), 0)) + int(batch.shape[0])
+                            if any(scale_flags):
+                                    pot_norm = batch[:, 0:1]
+                                    for j, i in enumerate(idxs):
+                                            if scale_flags[i]:
+                                                    sel = j
+                                                    scale = pot_norm[sel:sel+1, :]
+                                                    v1 = f1[sel:sel+1, :] * scale
+                                                    v2 = f2[sel:sel+1, :] * scale
+                                            else:
+                                                    v1 = f1[j:j+1, :]
+                                                    v2 = f2[j:j+1, :]
+                                            handles[i].set((v1, v2))
+                            else:
+                                    for j, i in enumerate(idxs):
+                                            handles[i].set((f1[j:j+1, :], f2[j:j+1, :]))
 
 def get_counters(self) -> Dict[str, int]:
 	return {str(k): int(v) for k, v in self._counters.items()}
