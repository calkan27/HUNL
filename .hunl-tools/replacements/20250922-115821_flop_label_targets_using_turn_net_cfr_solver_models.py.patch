--- a/cfr_solver_models.py
+++ b/cfr_solver_models.py
@@ -245,139 +245,139 @@
 			counterfactual_values[cluster_id] = [scalar] * len(ActionType)
 		return counterfactual_values
 
-	def flop_label_targets_using_turn_net(self, node):
-		K = int(self.num_clusters)
-		ps = node.public_state
-		if int(ps.current_round) != 1:
-			return [0.0] * K, [0.0] * K
-
-		root = GameNode(ps)
-		root.player_ranges = [dict(node.player_ranges[0]), dict(node.player_ranges[1])]
-		self.run_cfr(root)
-
-		def _normalize_range(r):
-			out = {}
-			s = 0.0
-			for k, v in dict(r).items():
-				out[int(k)] = float(v)
-				s += float(v)
-			if s > 0.0:
-				for k in list(out.keys()):
-					out[k] = out[k] / s
-			return out
-
-		def _rvec(r_dict):
-			vec = [0.0] * K
-			for i, p in dict(r_dict).items():
-				ii = int(i)
-				if 0 <= ii < K:
-					vec[ii] = float(p)
-			s = sum(vec) or 0.0
-			if s > 0.0:
-				for i in range(K):
-					vec[i] = vec[i] / s
-			return vec
-
-		def _turn_leaf_expectation(nd, r_us, r_opp):
-			board = list(nd.public_state.board_cards)
-			used = set(board)
-			if hasattr(nd.public_state, "hole_cards"):
-				for c in nd.public_state.hole_cards[0] + nd.public_state.hole_cards[1]:
-					used.add(c)
-			avail = [c for c in DECK if c not in used]
-			if not avail:
-				return [0.0] * K
-			total_initial = float(sum(nd.public_state.initial_stacks) if getattr(nd.public_state, "initial_stacks", None) else 1.0)
-			if total_initial <= 0.0:
-				total_initial = 1.0
-			pot_norm = float(nd.public_state.pot_size) / total_initial
-			r1t = torch.tensor([_rvec(r_us)], dtype=torch.float32, device=self.device)
-			r2t = torch.tensor([_rvec(r_opp)], dtype=torch.float32, device=self.device)
-			acc = [0.0] * K
-			den = 0.0
-			for tc in avail:
-				bvec = board_one_hot(board + [tc])
-				xt = torch.tensor([[pot_norm] + list(bvec) + _rvec(r_us) + _rvec(r_opp)], dtype=torch.float32, device=self.device)
-				p1, p2 = self.models["turn"](xt)
-				f1, f2 = self.models["turn"].enforce_zero_sum(r1t, r2t, p1, p2)
-				vec = f1[0].detach().cpu().tolist() if int(nd.public_state.current_player) == 0 else f2[0].detach().cpu().tolist()
-				for i in range(K):
-					acc[i] += float(vec[i])
-				den += 1.0
-			if den > 0.0:
-				for i in range(K):
-					acc[i] = acc[i] / den
-			return acc
-
-		def _allowed(ps_local, for_us):
-			return self._allowed_actions_agent(ps_local) if for_us else self._allowed_actions_opponent(ps_local)
-
-		def _update_range(nd, player, cid, a_idx):
-			self.update_player_range(nd, player, cid, a_idx)
-
-		def _ev_player(nd, player, depth, limit, r_us, r_opp):
-			if self._is_terminal(nd):
-				return float(self._calculate_terminal_utility(nd, player))
-			if int(nd.public_state.current_round) != 1 or depth >= limit:
-				vec = _turn_leaf_expectation(nd, r_us, r_opp)
-				rv = _rvec(r_us)
-				dp = 0.0
-				for i in range(K):
-					dp += float(rv[i]) * float(vec[i])
-				return dp * float(nd.public_state.pot_size)
-			cur = int(nd.public_state.current_player)
-			if cur == player:
-				menu = _allowed(nd.public_state, True)
-				values = self.cfr_values[nd]
-				ev = 0.0
-				for cid, prior in dict(nd.player_ranges[player]).items():
-					if float(prior) <= 0.0:
-						continue
-					base = values.compute_strategy(int(cid))
-					masked = self._mask_strategy(base, menu)
-					au = []
-					children = []
-					for a in menu:
-						ps2 = nd.public_state.update_state(nd, ActionType(a.value))  
-						ch = GameNode(ps2)
-						ch.player_ranges = [dict(nd.player_ranges[0]), dict(nd.player_ranges[1])]
-						_update_range(ch, player, int(cid), int(a.value))
-						children.append(ch)
-					for ch in children:
-						au.append(_ev_player(ch, player, depth + 1, limit, r_us, r_opp))
-					for i, a in enumerate(menu):
-						ev += float(prior) * float(masked[int(a.value)]) * float(au[i])
-				return ev
-			else:
-				menu = _allowed(nd.public_state, False)
-				best = None
-				for a in menu:
-					ps2 = nd.public_state.update_state(nd, ActionType(a.value))
-					ch = GameNode(ps2)
-					ch.player_ranges = [dict(nd.player_ranges[0]), dict(nd.player_ranges[1])]
-					val = _ev_player(ch, player, depth + 1, limit, r_us, r_opp)
-					if best is None or val < best:
-						best = val
-				return float(best if best is not None else 0.0)
-
-		root_pot = float(ps.pot_size) if float(ps.pot_size) > 0.0 else 1.0
-		r0 = _normalize_range(root.player_ranges[0])
-		r1 = _normalize_range(root.player_ranges[1])
-
-		t1 = [0.0] * K
-		t2 = [0.0] * K
-
-		for i in range(K):
-			root_i = GameNode(ps)
-			root_i.player_ranges = [{int(i): 1.0}, dict(r1)]
-			v = _ev_player(root_i, 0, 0, int(self.depth_limit), {int(i): 1.0}, dict(r1))
-			t1[i] = float(v) / root_pot
-
-		for j in range(K):
-			root_j = GameNode(ps)
-			root_j.player_ranges = [dict(r0), {int(j): 1.0}]
-			v = _ev_player(root_j, 1, 0, int(self.depth_limit), dict(r0), {int(j): 1.0})
-			t2[j] = float(v) / root_pot
-
-		return t1, t2
-
+    def flop_label_targets_using_turn_net(self, node):
+        K = int(self.num_clusters)
+        ps = node.public_state
+        if int(ps.current_round) != 1:
+            return [0.0] * K, [0.0] * K
+
+        root = GameNode(ps)
+        root.player_ranges = [dict(node.player_ranges[0]), dict(node.player_ranges[1])]
+        self.run_cfr(root)
+
+        def _normalize_range(r):
+            out = {}
+            s = 0.0
+            for k, v in dict(r).items():
+                out[int(k)] = float(v)
+                s += float(v)
+            if s > 0.0:
+                for k in list(out.keys()):
+                    out[k] = out[k] / s
+            return out
+
+        def _rvec(r_dict):
+            vec = [0.0] * K
+            for i, p in dict(r_dict).items():
+                ii = int(i)
+                if 0 <= ii < K:
+                    vec[ii] = float(p)
+            s = sum(vec) or 0.0
+            if s > 0.0:
+                for i in range(K):
+                    vec[i] = vec[i] / s
+            return vec
+
+        def _turn_leaf_expectation(nd, r_us, r_opp):
+            board = list(nd.public_state.board_cards)
+            used = set(board)
+            if hasattr(nd.public_state, "hole_cards"):
+                for c in nd.public_state.hole_cards[0] + nd.public_state.hole_cards[1]:
+                    used.add(c)
+            avail = [c for c in DECK if c not in used]
+            if not avail:
+                return [0.0] * K
+            total_initial = float(sum(nd.public_state.initial_stacks) if getattr(nd.public_state, "initial_stacks", None) else 1.0)
+            if total_initial <= 0.0:
+                total_initial = 1.0
+            pot_norm = float(nd.public_state.pot_size) / total_initial
+            r1t = torch.tensor([_rvec(r_us)], dtype=torch.float32, device=self.device)
+            r2t = torch.tensor([_rvec(r_opp)], dtype=torch.float32, device=self.device)
+            acc = [0.0] * K
+            den = 0.0
+            for tc in avail:
+                bvec = board_one_hot(board + [tc])
+                xt = torch.tensor([[pot_norm] + list(bvec) + _rvec(r_us) + _rvec(r_opp)], dtype=torch.float32, device=self.device)
+                p1, p2 = self.models["turn"](xt)
+                f1, f2 = self.models["turn"].enforce_zero_sum(r1t, r2t, p1, p2)
+                vec = f1[0].detach().cpu().tolist() if int(nd.public_state.current_player) == 0 else f2[0].detach().cpu().tolist()
+                for i in range(K):
+                    acc[i] += float(vec[i])
+                den += 1.0
+            if den > 0.0:
+                for i in range(K):
+                    acc[i] = acc[i] / den
+            return acc
+
+        def _allowed(ps_local, for_us):
+            return self._allowed_actions_agent(ps_local) if for_us else self._allowed_actions_opponent(ps_local)
+
+        def _update_range(nd, player, cid, a_idx):
+            self.update_player_range(nd, player, cid, a_idx)
+
+        def _ev_player(nd, player, depth, limit, r_us, r_opp):
+            if self._is_terminal(nd):
+                return float(self._calculate_terminal_utility(nd, player))
+            if int(nd.public_state.current_round) != 1 or depth >= limit:
+                vec = _turn_leaf_expectation(nd, r_us, r_opp)
+                rv = _rvec(r_us)
+                dp = 0.0
+                for i in range(K):
+                    dp += float(rv[i]) * float(vec[i])
+                return dp * float(nd.public_state.pot_size)
+            cur = int(nd.public_state.current_player)
+            if cur == player:
+                menu = _allowed(nd.public_state, True)
+                values = self.cfr_values[nd]
+                ev = 0.0
+                for cid, prior in dict(nd.player_ranges[player]).items():
+                    if float(prior) <= 0.0:
+                        continue
+                    base = values.compute_strategy(int(cid))
+                    masked = self._mask_strategy(base, menu)
+                    au = []
+                    children = []
+                    for a in menu:
+                        ps2 = nd.public_state.update_state(nd, Action(a))
+                        ch = GameNode(ps2)
+                        ch.player_ranges = [dict(nd.player_ranges[0]), dict(nd.player_ranges[1])]
+                        _update_range(ch, player, int(cid), int(a.value))
+                        children.append(ch)
+                    for ch in children:
+                        au.append(_ev_player(ch, player, depth + 1, limit, r_us, r_opp))
+                    for i, a in enumerate(menu):
+                        ev += float(prior) * float(masked[int(a.value)]) * float(au[i])
+                return ev
+            else:
+                menu = _allowed(nd.public_state, False)
+                best = None
+                for a in menu:
+                    ps2 = nd.public_state.update_state(nd, Action(a))
+                    ch = GameNode(ps2)
+                    ch.player_ranges = [dict(nd.player_ranges[0]), dict(nd.player_ranges[1])]
+                    val = _ev_player(ch, player, depth + 1, limit, r_us, r_opp)
+                    if best is None or val < best:
+                        best = val
+                return float(best if best is not None else 0.0)
+
+        root_pot = float(ps.pot_size) if float(ps.pot_size) > 0.0 else 1.0
+        r0 = _normalize_range(root.player_ranges[0])
+        r1 = _normalize_range(root.player_ranges[1])
+
+        t1 = [0.0] * K
+        t2 = [0.0] * K
+
+        for i in range(K):
+            root_i = GameNode(ps)
+            root_i.player_ranges = [{int(i): 1.0}, dict(r1)]
+            v = _ev_player(root_i, 0, 0, int(self.depth_limit), {int(i): 1.0}, dict(r1))
+            t1[i] = float(v) / root_pot
+
+        for j in range(K):
+            root_j = GameNode(ps)
+            root_j.player_ranges = [dict(r0), {int(j): 1.0}]
+            v = _ev_player(root_j, 1, 0, int(self.depth_limit), dict(r0), {int(j): 1.0})
+            t2[j] = float(v) / root_pot
+
+        return t1, t2
+
