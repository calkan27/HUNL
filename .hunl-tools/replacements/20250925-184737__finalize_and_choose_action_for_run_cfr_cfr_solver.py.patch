--- a/cfr_solver.py
+++ b/cfr_solver.py
@@ -645,80 +645,98 @@
 			upper = self._upper_from_cfvs(cfvs.get(opp_player, {}))
 			self._range_gadget_commit(node, upper)
 
-	def _finalize_and_choose_action_for_run_cfr(self, node, agent_player, ps):
-		regret_l2 = self._compute_regret_l2(node)
-		avg_ent = self._compute_avg_strategy_entropy(node)
-		zero_sum_res = self._compute_zero_sum_residual(node)
-
-		if getattr(self, "_zs_residual_samples", None):
-			total_abs = 0.0
-			for x in self._zs_residual_samples:
-				total_abs += abs(x)
-			zero_sum_res_mean = float(total_abs / float(len(self._zs_residual_samples)))
-		else:
-			zero_sum_res_mean = 0.0
-
-		self._last_diagnostics = {
-			"depth_limit": int(self.depth_limit),
-			"iterations": int(self.total_iterations),
-			"k1": float(self._soundness.get("k1", 0.0)),
-			"k2": float(self._soundness.get("k2", 0.0)),
-			"regret_l2": float(regret_l2),
-			"avg_strategy_entropy": float(avg_ent),
-			"cfv_calls": dict(self._diag_cfv_calls),
-			"zero_sum_residual": float(zero_sum_res),
-			"zero_sum_residual_mean": float(zero_sum_res_mean),
-			"constraint_mode": str(getattr(self, "constraint_mode", "sp")),
-		}
-
-		if ps.current_round == 0:
-			key1 = self._preflop_signature(node)
-			own = dict(node.player_ranges[agent_player])
-			s = 0.0
-			for v in own.values():
-				s += float(v)
-			if s > 0.0:
-				for k2 in list(own.keys()):
-					own[k2] = own[k2] / s
-			opp = (agent_player + 1) % 2
-			opp_cfvs = self.opponent_counterfactual_values.get(node, {}).get(opp, {})
-			upper = self._upper_from_cfvs(opp_cfvs)
-			self._preflop_cache_put(key1, own, upper)
-
-		allowed_actions = self._allowed_actions_agent(ps)
-		action_probs = self._mixed_action_distribution(node, agent_player, allowed_actions)
-
-		r = random.random()
-		cum = 0.0
-		chosen = allowed_actions[-1]
-		for a_type, p in zip(allowed_actions, action_probs):
-			cum += p
-			if r <= cum:
-				chosen = a_type
-				break
-
-		act = Action(chosen)
-
-		tmp_parent = GameNode(ps)
-		tmp_parent.player_ranges = [dict(node.player_ranges[0]), dict(node.player_ranges[1])]
-		tmp_parent.public_state.last_action = act
-
-		if hasattr(self, "update_tracking_on_own_action"):
-			self.update_tracking_on_own_action(
-				tmp_parent,
-				agent_player=agent_player,
-				counterfactual_values=self.opponent_counterfactual_values.get(node, {}),
-			)
-
-		new_ps = ps.update_state(node, act)
-		if new_ps is None:
-			print("update_state returned None in _finalize_and_choose_action_for_run_cfr.")
-			return act
-
-		node.public_state = new_ps
-		self.cfr_values = defaultdict(CFRValues)
-		self.iteration = 0
-		return act
+    def _finalize_and_choose_action_for_run_cfr(self, node, agent_player, ps):
+        regret_l2 = self._compute_regret_l2(node)
+        avg_ent = self._compute_avg_strategy_entropy(node)
+        zero_sum_res = self._compute_zero_sum_residual(node)
+        if getattr(self, "_zs_residual_samples", None):
+            total_abs = 0.0
+            for x in self._zs_residual_samples:
+                total_abs += abs(x)
+            zero_sum_res_mean = float(total_abs / float(len(self._zs_residual_samples)))
+        else:
+            zero_sum_res_mean = 0.0
+        self._last_diagnostics = {
+            "depth_limit": int(self.depth_limit),
+            "iterations": int(self.total_iterations),
+            "k1": float(self._soundness.get("k1", 0.0)),
+            "k2": float(self._soundness.get("k2", 0.0)),
+            "regret_l2": float(regret_l2),
+            "avg_strategy_entropy": float(avg_ent),
+            "cfv_calls": dict(self._diag_cfv_calls),
+            "zero_sum_residual": float(zero_sum_res),
+            "zero_sum_residual_mean": float(zero_sum_res_mean),
+            "constraint_mode": str(getattr(self, "constraint_mode", "sp")),
+        }
+        if ps.current_round == 0:
+            key1 = self._preflop_signature(node)
+            own = dict(node.player_ranges[agent_player])
+            s = 0.0
+            for v in own.values():
+                s += float(v)
+            if s > 0.0:
+                for k2 in list(own.keys()):
+                    own[k2] = own[k2] / s
+            opp = (agent_player + 1) % 2
+            opp_cfvs = self.opponent_counterfactual_values.get(node, {}).get(opp, {})
+            upper = self._upper_from_cfvs(opp_cfvs)
+            self._preflop_cache_put(key1, own, upper)
+        allowed_actions = self._allowed_actions_agent(ps)
+        action_probs = self._mixed_action_distribution(node, agent_player, allowed_actions)
+        r = random.random()
+        cum = 0.0
+        chosen = allowed_actions[-1]
+        for a_type, p in zip(allowed_actions, action_probs):
+            cum += p
+            if r <= cum:
+                chosen = a_type
+                break
+        act = Action(chosen)
+        tmp_parent = GameNode(ps)
+        tmp_parent.player_ranges = [dict(node.player_ranges[0]), dict(node.player_ranges[1])]
+        tmp_parent.public_state.last_action = act
+        if hasattr(self, "update_tracking_on_own_action"):
+            self.update_tracking_on_own_action(
+                tmp_parent,
+                agent_player=agent_player,
+                counterfactual_values=self.opponent_counterfactual_values.get(node, {}),
+            )
+        new_ps = ps.update_state(node, act)
+        if new_ps is None:
+            fallback_order = [
+                ActionType.CALL,
+                ActionType.POT_SIZED_BET,
+                ActionType.HALF_POT_BET,
+                ActionType.TWO_POT_BET,
+                ActionType.ALL_IN,
+                ActionType.FOLD,
+            ]
+            legal_set = set(allowed_actions)
+            chosen_fb = None
+            i = 0
+            while i < len(fallback_order):
+                a = fallback_order[i]
+                if a in legal_set:
+                    candidate = Action(a)
+                    ps2 = ps.update_state(node, candidate)
+                    if ps2 is not None:
+                        act = candidate
+                        new_ps = ps2
+                        chosen_fb = a
+                        break
+                i += 1
+            if new_ps is None and allowed_actions:
+                a = allowed_actions[0]
+                ps2 = ps.update_state(node, Action(a))
+                if ps2 is not None:
+                    act = Action(a)
+                    new_ps = ps2
+        if new_ps is None:
+            return act
+        node.public_state = new_ps
+        self.cfr_values = defaultdict(CFRValues)
+        self.iteration = 0
+        return act
 
 	def _cfv_terminal_case(self, node, player, depth, cache, node_key):
 		if self._is_terminal(node):
