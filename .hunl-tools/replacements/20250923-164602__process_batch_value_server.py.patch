--- a/value_server.py
+++ b/value_server.py
@@ -63,57 +63,58 @@
 				handles.append(hh)
 			self._process_batch(stages, xs, scale_flags, handles)
 
-	def _process_batch(
-		self,
-		stages: List[str],
-		xs: List[torch.Tensor],
-		scale_flags: List[bool],
-		handles: List[ResultHandle],
-	) -> None:
-		idx_by_stage: Dict[str, List[int]] = {}
-		for i, st in enumerate(stages):
-			idx_by_stage.setdefault(st, []).append(i)
+    def _process_batch(
+        self,
+        stages: List[str],
+        xs: List[torch.Tensor],
+        scale_flags: List[bool],
+        handles: List[ResultHandle],
+    ) -> None:
+        idx_by_stage: Dict[str, List[int]] = {}
+        for i, st in enumerate(stages):
+            idx_by_stage.setdefault(st, []).append(i)
 
-		for st, idxs in idx_by_stage.items():
-			model = self.models.get(st)
-			if model is None or len(idxs) == 0:
-				for i in idxs:
-					handles[i].set((torch.zeros(1, 0), torch.zeros(1, 0)))
-				continue
+        for st, idxs in idx_by_stage.items():
+            model = self.models.get(st)
+            if model is None or len(idxs) == 0:
+                for i in idxs:
+                    handles[i].set((torch.zeros(1, 0), torch.zeros(1, 0)))
+                continue
 
-			with torch.no_grad():
-				batch = torch.cat([xs[i].to(self.device) for i in idxs], dim=0)
+            with torch.no_grad():
+                batch = torch.cat([xs[i].to(self.device) for i in idxs], dim=0)
 
-				K = int(getattr(model, "num_clusters", 0))
-				insz = int(getattr(model, "input_size", batch.shape[1]))
-				board_dim = max(0, insz - (1 + 2 * K))
-				start_r1 = 1 + board_dim
-				end_r1 = start_r1 + K
-				start_r2 = end_r1
-				end_r2 = start_r2 + K
+                K = int(getattr(model, "num_clusters", 0))
+                insz = int(getattr(model, "input_size", batch.shape[1]))
+                board_dim = max(0, insz - (1 + 2 * K))
+                start_r1 = 1 + board_dim
+                end_r1 = start_r1 + K
+                start_r2 = end_r1
+                end_r2 = start_r2 + K
 
-				r1 = batch[:, start_r1:end_r1]
-				r2 = batch[:, start_r2:end_r2]
+                r1 = batch[:, start_r1:end_r1]
+                r2 = batch[:, start_r2:end_r2]
 
-				p1, p2 = model(batch)
-				f1, f2 = model.enforce_zero_sum(r1, r2, p1, p2)
+                p1, p2 = model(batch)
+                f1, f2 = model.enforce_zero_sum(r1, r2, p1, p2)
 
-				self._counters[str(st)] = int(self._counters.get(str(st), 0)) + int(batch.shape[0])
+                self._counters[str(st)] = int(self._counters.get(str(st), 0)) + int(batch.shape[0])
 
-				if any(scale_flags):
-					pot_norm = batch[:, 0:1]
-					for j, i in enumerate(idxs):
-						if scale_flags[i]:
-							scale = pot_norm[j:j + 1, :]
-							v1 = f1[j:j + 1, :] * scale
-							v2 = f2[j:j + 1, :] * scale
-						else:
-							v1 = f1[j:j + 1, :]
-							v2 = f2[j:j + 1, :]
-						handles[i].set((v1, v2))
-				else:
-					for j, i in enumerate(idxs):
-						handles[i].set((f1[j:j + 1, :], f2[j:j + 1, :]))
+                if any(scale_flags):
+                    pot_col = batch[:, 0:1]
+                    is_pot_size = bool(torch.mean(pot_col).item() > 1.0)
+                    for j, i in enumerate(idxs):
+                        if scale_flags[i] and is_pot_size:
+                            scale = pot_col[j:j + 1, :]
+                            v1 = f1[j:j + 1, :] * scale
+                            v2 = f2[j:j + 1, :] * scale
+                        else:
+                            v1 = f1[j:j + 1, :]
+                            v2 = f2[j:j + 1, :]
+                        handles[i].set((v1, v2))
+                else:
+                    for j, i in enumerate(idxs):
+                        handles[i].set((f1[j:j + 1, :], f2[j:j + 1, :]))
 
 	def query(
 		self,
