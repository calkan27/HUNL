--- a/value_server.py
+++ b/value_server.py
@@ -49,27 +49,29 @@
 		if join and self._thr is not None:
 			self._thr.join(timeout=1.0)
 
-	def _run(self) -> None:
-		while not self._stop.is_set():
-			try:
-				stage0, x0, scale0, h0 = self._q.get(timeout=0.001)
-			except queue.Empty:
-				continue
-			stages: List[str] = [stage0]
-			xs: List[torch.Tensor] = [x0]
-			scale_flags: List[bool] = [scale0]
-			handles: List[ResultHandle] = [h0]
-			deadline = time.time() + (self.max_wait_ms / 1000.0)
-			while len(xs) < self.max_batch and time.time() < deadline:
-				try:
-					stg, xt, sc, hh = self._q.get_nowait()
-				except queue.Empty:
-					break
-				stages.append(stg)
-				xs.append(xt)
-				scale_flags.append(sc)
-				handles.append(hh)
-			self._process_batch(stages, xs, scale_flags, handles)
+    def _run(self) -> None:
+        while not self._stop.is_set():
+            try:
+                stage0, x0, scale0, t0, h0 = self._q.get(timeout=0.001)
+            except queue.Empty:
+                continue
+            stages: List[str] = [stage0]
+            xs: List[torch.Tensor] = [x0]
+            scale_flags: List[bool] = [scale0]
+            totals: List[Optional[float]] = [t0]
+            handles: List[ResultHandle] = [h0]
+            deadline = time.time() + (self.max_wait_ms / 1000.0)
+            while len(xs) < self.max_batch and time.time() < deadline:
+                try:
+                    stg, xt, sc, tt, hh = self._q.get_nowait()
+                except queue.Empty:
+                    break
+                stages.append(stg)
+                xs.append(xt)
+                scale_flags.append(sc)
+                totals.append(tt)
+                handles.append(hh)
+            self._process_batch(stages, xs, scale_flags, totals, handles)
 
 	def _process_batch(
 		self,
