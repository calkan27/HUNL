--- a/value_server.py
+++ b/value_server.py
@@ -73,74 +73,81 @@
 				handles.append(hh)
 			self._process_batch(stages, xs, scale_flags, totals, handles)
 
-	def _process_batch(
-		self,
-		stages: List[str],
-		xs: List[torch.Tensor],
-		scale_flags: List[bool],
-		totals: List[Optional[float]],
-		handles: List[ResultHandle],
-	) -> None:
-		idx_by_stage: Dict[str, List[int]] = {}
-		for i, st in enumerate(stages):
-			idx_by_stage.setdefault(st, []).append(i)
+    def _process_batch(
+        self,
+        stages: List[str],
+        xs: List[torch.Tensor],
+        scale_flags: List[bool],
+        totals: List[Optional[float]],
+        handles: List[ResultHandle],
+        ) -> None:
 
-		for st, idxs in idx_by_stage.items():
-			model = self.models.get(st)
-			if model is None or len(idxs) == 0:
-				for i in idxs:
-					handles[i].set((torch.zeros(1, 0), torch.zeros(1, 0)))
-				continue
+        idx_by_stage: Dict[str, List[int]] = {}
+        for i, st in enumerate(stages):
+            idx_by_stage.setdefault(st, []).append(i)
 
-			with torch.no_grad():
-				batch = torch.cat([xs[i].to(self.device) for i in idxs], dim=0)
+        for st, idxs in idx_by_stage.items():
+            model = self.models.get(st)
+            if model is None or len(idxs) == 0:
+                for i in idxs:
+                    handles[i].set((torch.zeros(1, 0), torch.zeros(1, 0)))
+                continue
 
-				K = int(getattr(model, "num_clusters", 0))
-				insz = int(getattr(model, "input_size", batch.shape[1]))
-				board_dim = max(0, insz - (1 + 2 * K))
-				start_r1 = 1 + board_dim
-				end_r1 = start_r1 + K
-				start_r2 = end_r1
-				end_r2 = start_r2 + K
+            with torch.no_grad():
+                batch = torch.cat([xs[i].to(self.device) for i in idxs], dim=0)
 
-				r1 = batch[:, start_r1:end_r1]
-				r2 = batch[:, start_r2:end_r2]
+                K = int(getattr(model, "num_clusters", 0))
+                insz = int(getattr(model, "input_size", batch.shape[1]))
+                board_dim = max(0, insz - (1 + 2 * K))
+                start_r1 = 1 + board_dim
+                end_r1 = start_r1 + K
+                start_r2 = end_r2 = start_r1 + 2 * K
 
-				p1, p2 = model(batch)
-				f1, f2 = model.enforce_zero_sum(r1, r2, p1, p2)
+                r1 = batch[:, start_r1:end_r1]
+                r2 = batch[:, end_r1:end_r2]
 
-				self._counters[str(st)] = int(self._counters.get(str(st), 0)) + int(batch.shape[0])
+                p1, p2 = model(batch)
+                f1, f2 = model.enforce_zero_sum(r1, r2, p1, p2)
 
-				s1 = torch.sum(r1 * f1, dim=1)
-				s2 = torch.sum(r2 * f2, dim=1)
-				res = torch.abs(s1 + s2).detach().cpu()
+                self._counters[str(st)] = int(self._counters.get(str(st), 0)) + int(batch.shape[0])
 
-				stats_stage = self._resid_stats.setdefault(str(st), {"max": 0.0, "sum": 0.0, "count": 0.0})
-				stats_over = self._resid_stats.setdefault("overall", {"max": 0.0, "sum": 0.0, "count": 0.0})
-				mx = float(torch.max(res).item()) if res.numel() > 0 else 0.0
-				sm = float(torch.sum(res).item()) if res.numel() > 0 else 0.0
-				ct = float(res.numel())
+                s1 = torch.sum(r1 * f1, dim=1)
+                s2 = torch.sum(r2 * f2, dim=1)
+                res = torch.abs(s1 + s2).detach().cpu()
 
-				if mx > stats_stage["max"]:
-					stats_stage["max"] = mx
-				stats_stage["sum"] += sm
-				stats_stage["count"] += ct
+                stats_stage = self._resid_stats.setdefault(str(st), {"max": 0.0, "sum": 0.0, "count": 0.0})
+                stats_over = self._resid_stats.setdefault("overall", {"max": 0.0, "sum": 0.0, "count": 0.0})
+                mx = float(torch.max(res).item()) if res.numel() > 0 else 0.0
+                sm = float(torch.sum(res).item()) if res.numel() > 0 else 0.0
+                ct = float(res.numel())
+                if mx > stats_stage["max"]:
+                    stats_stage["max"] = mx
+                stats_stage["sum"] += sm
+                stats_stage["count"] += ct
+                if mx > stats_over["max"]:
+                    stats_over["max"] = mx
+                stats_over["sum"] += sm
+                stats_over["count"] += ct
 
-				if mx > stats_over["max"]:
-					stats_over["max"] = mx
-				stats_over["sum"] += sm
-				stats_over["count"] += ct
+                offsets = []
+                acc = 0
+                for i in idxs:
+                    offsets.append(acc)
+                    acc += int(xs[i].shape[0])
 
-				for j, i in enumerate(idxs):
-					out1 = f1[j:j + 1, :].clone()
-					out2 = f2[j:j + 1, :].clone()
-					if bool(scale_flags[i]):
-						pot_norm = float(xs[i].detach().cpu().view(1, -1)[0, 0].item())
-						ti = totals[i] if (totals[i] is not None and float(totals[i]) > 0.0) else float(self.total_initial_default)
-						scale = pot_norm * ti
-						out1 = out1 * scale
-						out2 = out2 * scale
-					handles[i].set((out1, out2))
+                for j, i in enumerate(idxs):
+                    start = offsets[j]
+                    count = int(xs[i].shape[0])
+                    out1 = f1[start:start + count, :].clone()
+                    out2 = f2[start:start + count, :].clone()
+                    if bool(scale_flags[i]):
+                        pot_norm = float(xs[i].detach().cpu().view(xs[i].shape[0], -1)[0, 0].item())
+                        ti = totals[i] if (totals[i] is not None and float(totals[i]) > 0.0) else float(self.total_initial_default)
+                        scale = pot_norm * ti
+                        out1 = out1 * scale
+                        out2 = out2 * scale
+                    handles[i].set((out1, out2))
+
 
 	def query(
 		self,
