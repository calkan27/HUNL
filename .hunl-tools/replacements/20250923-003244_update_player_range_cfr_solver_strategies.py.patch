--- a/cfr_solver_strategies.py
+++ b/cfr_solver_strategies.py
@@ -71,50 +71,52 @@
 
 		return _recurse(node)
 
-	def update_player_range(self, node: GameNode, player: int, cluster_id: int, action_index: int):
-		values = self.cfr_values[node]
-		num_actions = len(ActionType)
-		if player not in (0, 1):
-			return
-		priors = node.player_ranges[player]
-		post = {}
-		norm = 0.0
-		for cid, prior in priors.items():
-			current_strategy = (
-				values.compute_strategy(cid) if cid in values.cumulative_positive_regret else values.strategy.get(cid, [1.0 / num_actions] * num_actions)
-			)
-			if player == (node.public_state.current_player + 1) % 2:
-				like = 1.0
-			else:
-				if action_index < 0 or action_index >= len(current_strategy):
-					like = 0.0
-				else:
-					like = current_strategy[action_index]
-			weight = prior * like
-			post[cid] = weight
-			norm = norm + weight
-
-		if norm <= 0.0:
-			total_prior = 0.0
-			for cid in priors:
-				total_prior = total_prior + priors[cid]
-			if total_prior <= 0.0:
-				k = len(priors)
-				if k > 0:
-					u = 1.0 / k
-					for cid in post:
-						post[cid] = u
-				else:
-					post = {}
-			else:
-				for cid in post:
-					post[cid] = priors[cid] / total_prior
-		else:
-			for cid in post:
-				post[cid] = post[cid] / norm
-
-		node.player_ranges[player] = post
-
+    def update_player_range(self, node: GameNode, player: int, cluster_id: int, action_index: int):
+        values = self.cfr_values[node]
+        num_actions = len(ActionType)
+        if player not in (0, 1):
+            return
+        if not hasattr(node, "_priors_baseline"):
+            node._priors_baseline = [{}, {}]
+        if not node._priors_baseline[player]:
+            node._priors_baseline[player] = dict(node.player_ranges[player])
+        priors = node.player_ranges[player]
+        post = {}
+        norm = 0.0
+        for cid, prior in priors.items():
+            current_strategy = (
+                values.compute_strategy(cid) if cid in values.cumulative_positive_regret else values.strategy.get(cid, [1.0 / num_actions] * num_actions)
+            )
+            if player == (node.public_state.current_player + 1) % 2:
+                like = 1.0
+            else:
+                if action_index < 0 or action_index >= len(current_strategy):
+                    like = 0.0
+                else:
+                    like = current_strategy[action_index]
+            weight = prior * like
+            post[cid] = weight
+            norm += weight
+        if norm <= 0.0:
+            base = node._priors_baseline[player] if isinstance(getattr(node, "_priors_baseline", None), list) else priors
+            total_prior = 0.0
+            for _, v in base.items():
+                total_prior += float(v)
+            if total_prior <= 0.0:
+                k = len(base)
+                if k > 0:
+                    u = 1.0 / k
+                    for cid in base:
+                        post[cid] = u
+                else:
+                    post = {}
+            else:
+                for cid in base:
+                    post[cid] = float(base[cid]) / float(total_prior)
+        else:
+            for cid in post:
+                post[cid] = post[cid] / norm
+        node.player_ranges[player] = post
 
     def _allowed_actions_agent(self, ps):
         self._ensure_sparse_schedule()
