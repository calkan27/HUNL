--- a/hunl/solving/cfr_solver.py
+++ b/hunl/solving/cfr_solver.py
@@ -223,82 +223,80 @@
 		cache[node_key] = counterfactual_values
 		return counterfactual_values
 
-	def _calculate_counterfactual_utility(self, node, player, depth):
-		if self._is_terminal(node):
-			return self._calculate_terminal_utility(node, player)
-
-		stage = self.get_stage(node)
-		if (depth >= self.depth_limit) and (stage in ("preflop", "flop")):
-			preds = self.predict_counterfactual_values(node, player)
-			sc = 1.0 if bool(getattr(self, "_label_pot_fraction", False)) else float(node.public_state.pot_size)
-			ev = 0.0
-			total = 0.0
-			for cid, p in node.player_ranges[player].items():
-				if cid in preds:
-					v = preds[cid][0]
-					val = float(v[0]) * sc if isinstance(v, (list, tuple)) else float(v) * sc
-					ev += p * val
-					total += p
-			if total > 0:
-				return ev / total
-			else:
-				return 0.0
-
-		current_player = node.current_player
-		expected_value = 0.0
-
-		if current_player == player:
-			allowed_actions = self._allowed_actions_agent(node.public_state)
-			for cluster_id, cluster_prob in node.player_ranges[player].items():
-				if cluster_prob == 0.0:
-					continue
-				values = self.cfr_values[node]
-				base_strategy = values.compute_strategy(cluster_id)
-				strategy = self._mask_strategy(base_strategy, allowed_actions)
-				action_utilities = []
-				for a_type in allowed_actions:
-					a_idx = a_type.value
-					if a_idx in values.pruned_actions[cluster_id]:
-						action_utilities.append(0.0)
-						continue
-					action = Action(a_type)
-					ps2 = node.public_state.update_state(node, action)
-					if ps2 is None:
-						action_utilities.append(0.0)
-						continue
-					child_node = GameNode(ps2)
-					child_node.player_ranges = copy.deepcopy(node.player_ranges)
-					if int(ps2.current_round) > int(node.public_state.current_round):
-						self.lift_ranges_after_chance(child_node)
-					self.update_player_range(child_node, player, cluster_id, a_idx)
-					utility = self._calculate_counterfactual_utility(child_node, player, depth + 1)
-					action_utilities.append(utility)
-				i = 0
-				while i < len(allowed_actions):
-					a_idx = allowed_actions[i].value
-					expected_value += cluster_prob * strategy[a_idx] * action_utilities[i]
-					i += 1
-		else:
-			allowed_actions = self._allowed_actions_opponent(node.public_state)
-			best = None
-			for a_type in allowed_actions:
-				act = Action(a_type)
-				ps2 = node.public_state.update_state(node, act)
-				if ps2 is None:
-					continue
-				ch = GameNode(ps2)
-				ch.player_ranges = copy.deepcopy(node.player_ranges)
-				if int(ps2.current_round) > int(node.public_state.current_round):
-					self.lift_ranges_after_chance(ch)
-				val = self._calculate_counterfactual_utility(ch, player, depth + 1)
-				if (best is None) or (val < best):
-					best = val
-			if best is not None:
-				expected_value += float(best)
-			else:
-				expected_value += 0.0
-
-		return expected_value
+    def _calculate_counterfactual_utility(self, node, player, depth):
+        if self._is_terminal(node):
+            return self._calculate_terminal_utility(node, player)
+        stage = self.get_stage(node)
+        root = getattr(self, "_root_stage", stage)
+        cross_round_cut = (root in ("preflop", "flop")) and (stage != root)
+        if ((depth >= self.depth_limit) and (stage in ("preflop", "flop"))) or cross_round_cut:
+            preds = self.predict_counterfactual_values(node, player)
+            sc = 1.0 if bool(getattr(self, "_label_pot_fraction", False)) else float(node.public_state.pot_size)
+            ev = 0.0
+            total = 0.0
+            for cid, p in node.player_ranges[player].items():
+                if cid in preds:
+                    v = preds[cid][0]
+                    val = float(v[0]) * sc if isinstance(v, (list, tuple)) else float(v) * sc
+                    ev += p * val
+                    total += p
+            if total > 0:
+                return ev / total
+            else:
+                return 0.0
+        current_player = node.current_player
+        expected_value = 0.0
+        if current_player == player:
+            allowed_actions = self._allowed_actions_agent(node.public_state)
+            for cluster_id, cluster_prob in node.player_ranges[player].items():
+                if cluster_prob == 0.0:
+                    continue
+                values = self.cfr_values[node]
+                base_strategy = values.compute_strategy(cluster_id)
+                strategy = self._mask_strategy(base_strategy, allowed_actions)
+                action_utilities = []
+                for a_type in allowed_actions:
+                    a_idx = a_type.value
+                    if a_idx in values.pruned_actions[cluster_id]:
+                        action_utilities.append(0.0)
+                        continue
+                    action = Action(a_type)
+                    ps2 = node.public_state.update_state(node, action)
+                    if ps2 is None:
+                        action_utilities.append(0.0)
+                        continue
+                    child_node = GameNode(ps2)
+                    child_node.player_ranges = copy.deepcopy(node.player_ranges)
+                    if int(ps2.current_round) > int(node.public_state.current_round):
+                        self.lift_ranges_after_chance(child_node)
+                    self.update_player_range(child_node, player, cluster_id, a_idx)
+                    utility = self._calculate_counterfactual_utility(child_node, player, depth + 1)
+                    action_utilities.append(utility)
+                i = 0
+                while i < len(allowed_actions):
+                    a_idx = allowed_actions[i].value
+                    expected_value += cluster_prob * strategy[a_idx] * action_utilities[i]
+                    i += 1
+        else:
+            allowed_actions = self._allowed_actions_opponent(node.public_state)
+            best = None
+            for a_type in allowed_actions:
+                act = Action(a_type)
+                ps2 = node.public_state.update_state(node, act)
+                if ps2 is None:
+                    continue
+                ch = GameNode(ps2)
+                ch.player_ranges = copy.deepcopy(node.player_ranges)
+                if int(ps2.current_round) > int(node.public_state.current_round):
+                    self.lift_ranges_after_chance(ch)
+                val = self._calculate_counterfactual_utility(ch, player, depth + 1)
+                if (best is None) or (val < best):
+                    best = val
+            if best is not None:
+                expected_value += float(best)
+            else:
+                expected_value += 0.0
+        return expected_value
 
 	def _update_regret(self, node, player, cfv_by_action):
 		values = self.cfr_values[node]
